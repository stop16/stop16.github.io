---
layout: post
title: "2022년도 스마트로봇 경진대회 참여기 - 1편"
subtitle: "프로젝트 계획 및 구현 준비"
categories: ["스마트로봇 경진대회"]
---

## Intro

이번 포스트에서는 대회에 참가하기 위한 계획 설립 및 구현 준비과정을 작성하겠다.

## 대회 분석 및 계획 설립

### 스마트로봇 경진대회에 대해 알아보자
대회의 과제를 수행하기 위해서는, 대회에 관해서 잘 알아야 한다. 스마트로봇 경진대회는 [대한전자공학회][1]와 대림대학교에서 주최하고, (주)로보웰코리아에서 주관하는 대회이다. 이 외의 정보는 다음과 같다.

|이름|내용|
|--|--|
|대회 명칭|2022년도 제 10회 전국 대학교 스마트로봇 경진대회|
|후원|과학기술정보통신부, 경기도, 대한전자공학회|
|장소|대림대학교 한림관 체육관|
|일시|2022년 6월 23일(목) 09:00~17:00|
|대회 과제|스마트 물류 자동화를 위한 무인반송로봇(AGV) 구현|

대략적인 정보를 알았으니, 규정집을 확인해 대회 과제를 분석해보자.

### 규정집

많은 대회에 나갈 때마다 규정집의 규칙이나 경기 방식 등을 확실하게 확인해야 대회에서 성과를 낼 수 있다. 

이번 대회의 규정집은 [이곳][2]에서 확인이 가능하다. 아무나 해당 링크에 접근이 가능하니 해당 대회에 관심이 있는 분은 링크에서 규정집을 다운받아서 보시면 좋을 것 같다. 아닌 분들은 하단의 내용을 보시면 되겠다.

규정집을 읽었을 때, 대회의 과제는 크게 두 가지 기능의 구현으로 정리 가능했다.
- 오브젝트(화물) 운반
- 이동(라인 트레이싱)

### 정리 1: 오브젝트(화물) 운반

- 오브젝트는 총 두 종류가 있다.
  - 오브젝트: 대회에서 로봇이 옮겨야 할 오브젝트이다.
  - 오브젝트 기둥: 로봇은 오브젝트 기둥 위에 오브젝트를 올려놓으면 된다.
- 오브젝트는 색상이 있다.
  - 오브젝트: R(빨강),G(초록),B(파랑)
  - 오브젝트 기둥: R,G,B,Y(노랑)
  - 오브젝트를 잡아서, 같은 색상의 오브젝트 기둥 위에 올려놓으면 된다.
- 오브젝트의 크기
  - 오브젝트: 50mm * 50mm * 50mm (가로 * 세로 * 높이)
  - 오브젝트 기둥: 50mm * 50mm * 100mm (가로 * 세로 * 높이)

생각보다 단순하다. 색상을 인식해서, 오브젝트를 잡아다가 기둥 오브젝트 위에 올려놓으면 된다. 심지어 잡아야 할 오브젝트도 그리 크지 않다! 그런데, 노랑 오브젝트는 왜 있는가?  
쉬운 이해를 위해 예시를 들면, 빨강 오브젝트 기둥 위에 빨강 오브젝트를 올려놓으려 할 때 다른 색상의 오브젝트가 있을 수 있다. 그럴때, 임시 저장 공간과 같은 역할을 할 수 있도록 배치가 된 것으로 보인다.  

### 정리 2: 이동(라인 트레이싱)

- 경기장은 500mm x 500mm의 정사각형으로 구성된 출발 및 도착 구역, 과제를 수행하는 2160mm x 700mm의 직사각형으로 구성된 구역(임무 구역)으로 나뉜다.
- 각 구역은 모두 20mm 폭을 가지는 검정색 선으로 구성되어 있으며, 경기장의 배경 색은 흰색이다.
- 임무 구역은 2160mm의 가로 영역을 검정색 선으로 4분할 하였으며, 700mm의 세로 영역을 역시 검정색 선으로 2분할 하였다.
- 따라서 검정색 선이 만나게 되어 교차점이 생성되게 되는데, 중앙이 아닌 상단 및 하단 교차점에는 기둥 오브젝트가 배치된다.

글로 풀어써서 이해가 잘 안된다. 백문이 불여일견이니, 아래의 경기장 사진을 확인하시면 편하다.

![map](https://github.com/stop16/stop16.github.io/assets/106593420/65ee3e9d-5917-4913-9fa0-9e7a5d3d1b53)

핵심은 출발 구역에서 임무 구역으로 이동 후, 라인 트레이싱으로 이동 및 과제 수행을 한 뒤, 도착 구역으로 들어가는 것이다. 따라서, 라인 트레이싱이 가능하게 IR센서 배치를 한 후, 라인 트레이싱만 구현하면 되겠다.

## 구현 준비과정

앞선 챕터들에서 구현을 하기 위해서는 다음과 같은 기술들이 필요하다는 것을 알았다.
- [오브젝트 색상의 인식](#오브젝트-색상의-인식) 및 그립 구조의 제작
- [라인 트레이싱](#라인-트레이싱)

이 내용들 중, 그립 구조는 정말 감사하게도 선배님들이 도맡아 처리해 주셨으니, 나머지 내용들에 대해 알아보자.

### 오브젝트 색상의 인식
색 인식은 CV(Computer Vision)의 영역이다. 나는 OpenCV로 영상 처리를 이전에 몇 번 해보았으나, 색 인식만으로 오브젝트를 인식해본 적은 없다. 따라서 관련된 내용을 학습하려던 와중, 아주 좋은 물건을 받았다. 

![huskylens](https://github.com/stop16/stop16.github.io/assets/106593420/4b51f15a-fb7f-4daf-b134-34cc2a6f1b96)

바로 허스키 렌즈이다.  
제조사인 DFROBOT사의 공식 [wiki][3]의 introduction에 소개된 대로, 쉽게 쓸 수 있는 AI 머신 비전 센서라고 한다. 기능 또한 총 일곱 개 존재하는데, 얼굴 인식, 오브젝트 트래킹, 오브젝트 인식, 라인 트래킹, 색 인식, 태그 인식, 그리고 오브젝트 분류라고 한다. 허스키 렌즈를 사용함으로써 색 인식을 해야 하니 라즈베리파이와 같은 SBC에다가 OpenCV 사용해서 코드 작성하고, 카메라와 SBC 고정할 구조물까지 만드는 고생을 덜 수 있다. 아주 감사하다.

결론적으로, 오브젝트 색상의 인식은 허스키 렌즈를 사용해서 색을 학습시키고, 인식하도록 하면 될 것 같다.

### 라인 트레이싱
라인 트레이싱은 로봇이 경기장의 검은 선을 따라가도록 하기 위해 필요한 기술이고, 대부분 적외선 센서를 사용해서 구현한다. 나 또한 적외선 센서를 사용해 구현할 예정이다. 


라인 트레이싱 로직은 센서의 개수에 따라 변화한다. 간단하게 이어진 선만 따라가게 하기 위해서는 한 개면 충분하지만, 이번 대회와 같이 교차점을 인식해서 로봇의 현재 위치를 추정할 필요가 있는 경우, 라인 트레이싱을 하면서 교차점을 인식할 수 있어야 한다. 이를 위해서는 항상 양쪽에 각각 한 개 이상의 센서 여유가 필요하므로, 최소 세개의 적외선 센서를 사용하여 라인 트레이싱을 해야 한다. 따라서 총 세개의 적외선 센서를 사용하는 라인 트레이서를 만들기로 하였다. 이때, 적외선 센서는 다음과 같이 배치된다.

- 좌측 적외선 센서
- 중앙 적외선 센서
- 우측 적외선 센서

그렇다면, 적외선 센서에 직선으로 된 라인이 걸치는 경우는 다음과 같다.

1. 좌측 적외선 센서보다 왼쪽에 라인이 있는 경우
2. 죄측 적외선 센서에 라인이 맞닿은 경우
3. 좌측 적외선 센서와 중앙 적외선 센서 사이에 라인이 있는 경우
4. 중앙 적외선 센서에 라인이 맞닿은 경우
5. 중앙 적외선 센서와 우측 적외선 센서 사이에 라인이 있는 경우
6. 우측 적외선 센서에 라인이 맞닿은 경우
7. 우측 적외선 센서보다 오른쪽에 라인이 있는 경우

교차점을 고려하면 한 가지의 추가가 가능하다.

8. 모든 적외선 센서가 라인에 걸치는 경우

이러한 경우들을 정리하면, 교차점으로부터 교차점까지 한 칸 이동 후 정지하는 함수에는 네 가지의 경우와 행동을 정리할 수 있다.
1. 모든 적외선 센서가 라인에 걸쳤을 경우  
   이러한 경우, 로봇이 교차점에 닿은 것으로 간주할 수 있다.  
   따라서 교차점간의 이동이 완료된 상태이므로 정지한다.  
2. 좌측 적외선 센서가 라인에 걸쳤을 경우  
   로봇이 오른쪽으로 치우쳤다고 볼 수 있다. 왼쪽 센서만 닿았다는 것은, 오른쪽으로 로봇이 이동하였다는 것이기 때문이다.  
   로봇을 왼쪽으로 이동하게끔 만들면 다시 중앙으로 이동할 수 있다.  
3. 우측 적외선 센서가 라인에 걸쳤을 경우  
   로봇이 오른쪽으로 치우쳤다고 볼 수 있다.  
   로봇을 오른쪽으로 이동하게 만들면 된다.
4. 아무 적외선 센서가 라인에 걸치지 않았을 경우  
   센서에 라인이 인식되지 않는다면, 위의 1,3,4,5,7번 경우에 해당한다. 이 중에서 1,7번 경우에 집중하자.  
   상식적으로, 이러한 경우에는 정지를 해야 한다. 그래야 로봇이 잘못된 방향으로 계속 전진하는 것을 막을 수 있다.  
   하지만 이는 적외선 센서 사이의 간격 문제로 연결된다.  
   적외선 센서 사이의 간격을 선의 두께인 약 20mm보다 좁을 경우, 교차점에 맞닿았다고 잘못 인식할 가능성이 높아진다.  
   그렇다고 20mm보다 넓히면, 센서 사이에 라인이 걸쳐 아무 라인도 인식되지 않아 로봇이 정지한다.
   따라서, 적당한 간격을 만들어야 한다.  
   그런데, 우리에게 주어진 시간은 시험기간을 포함한 한달 남짓이었다. 센서 간격은 적당히 하고, 소프트웨어적으로 보완하는 것이 좋을 것이라 판단했다.  
   라인이 세 센서 사이에 위치하게만 하면, 로봇이 완전 경기장을 벗어날 일은 없지 않을까?  
   그래서 위의 세 가지 외에는 모두 전진하도록 했다.

이렇게 라인 트레이싱의 로직 또한 완성하였다.  

## 마무리

가장 핵심적인 기술들은 위의 내용처럼 구현하면 되겠다고 생각했다.  
나머지 구현해야 할 부분은 컨트롤러 보드의 제어, 서보모터의 제어와 같은 간단한 부분이다. 다음 글에서는 로봇의 제어 구현 과정을 설명하면 될 것 같다.


[1]: https://www.theieie.org/
[2]: https://cafe.naver.com/robowell/298
[3]: https://wiki.dfrobot.com/HUSKYLENS_V1.0_SKU_SEN0305_SEN0336